{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d0e4033",
   "metadata": {},
   "source": [
    "# Question Answering – Évaluation du modèle\n",
    "\n",
    "Ce notebook évalue les performances du modèle fine-tuné\n",
    "sur le dataset SQuAD (Exact Match, F1-score et temps d’inférence).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3048dfed",
   "metadata": {},
   "source": [
    "## Objectifs\n",
    "\n",
    "- Charger le modèle fine-tuné\n",
    "- Évaluer les performances sur le jeu de validation\n",
    "- Calculer les métriques Exact Match et F1\n",
    "- Mesurer le temps d’inférence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89f6fdea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aissi\\OneDrive - De Vinci\\A5\\UVSQ\\S2\\Fouille de données\\qa-project\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83172f68",
   "metadata": {},
   "source": [
    "## Chargement des données préprocessées\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3bf7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aissi\\OneDrive - De Vinci\\A5\\UVSQ\\S2\\Fouille de données\\qa-project\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:130: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\aissi\\.cache\\huggingface\\hub\\datasets--squad. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Generating train split: 100%|██████████| 87599/87599 [00:00<00:00, 490288.54 examples/s]\n",
      "Generating validation split: 100%|██████████| 10570/10570 [00:00<00:00, 297506.30 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Note: tokenized_datasets n'est pas utilisé pour l'évaluation.\n",
    "# Nous travaillons directement avec le raw_datasets afin de tokenizer \n",
    "# les nouveaux exemples avec la même configuration que lors de l'inférence.\n",
    "\n",
    "from datasets import load_dataset\n",
    "raw_datasets = load_dataset(\"squad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad53c07",
   "metadata": {},
   "source": [
    "## Chargement du modèle fine-tuné\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c6e6c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 102/102 [00:00<00:00, 429.89it/s, Materializing param=qa_outputs.weight]                                     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForQuestionAnswering(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSelfAttention(\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"outputs/checkpoints/distilbert/final\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_path)\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5523769f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForQuestionAnswering(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSelfAttention(\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377357f4",
   "metadata": {},
   "source": [
    "## Métriques SQuAD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2520da38",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"squad\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e3e16f",
   "metadata": {},
   "source": [
    "## Fonction d’inférence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a1a55b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_score(example):\n",
    "    inputs = {\n",
    "        \"input_ids\": torch.tensor(example[\"input_ids\"]).unsqueeze(0).to(device),\n",
    "        \"attention_mask\": torch.tensor(example[\"attention_mask\"]).unsqueeze(0).to(device)\n",
    "    }\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    start_logits = outputs.start_logits.squeeze()\n",
    "    end_logits = outputs.end_logits.squeeze()\n",
    "\n",
    "    start_idx = torch.argmax(start_logits)\n",
    "    end_idx = torch.argmax(end_logits)\n",
    "\n",
    "    score = start_logits[start_idx] + end_logits[end_idx]\n",
    "\n",
    "    return start_idx.item(), end_idx.item(), score.item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb6bca3",
   "metadata": {},
   "source": [
    "## Évaluation sur le jeu de validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9ce536",
   "metadata": {},
   "source": [
    "### Méthodologie\n",
    "\n",
    "- **Sous-ensemble d'évaluation** : L'évaluation est effectuée sur un sous-ensemble de 500 exemples afin de réduire le temps de calcul tout en conservant une estimation représentative.\n",
    "\n",
    "- **Fenêtre de contexte unique** : Pour limiter le temps de calcul, l'évaluation utilise une seule fenêtre de contexte (max_length=384) sans sliding window. Cela peut légèrement sous-estimer les performances sur les contextes plus longs.\n",
    "\n",
    "- **Exactitude (Exact Match) du span prédit** : Contrairement à Exact Match exact au token près, on compare les textes décodés pour évaluer la pertinence de la réponse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac89c07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 500\n",
    "validation_set = raw_datasets[\"validation\"].select(range(min(n_samples, len(raw_datasets[\"validation\"]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe16012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_scores = []\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "for example in validation_set:\n",
    "    # Tokenize the raw example\n",
    "    encoded = tokenizer(\n",
    "        example[\"question\"],\n",
    "        example[\"context\"],\n",
    "        truncation=True,\n",
    "        max_length=384,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**{k: v.to(device) for k, v in encoded.items()})\n",
    "    \n",
    "    start_logits = outputs.start_logits[0]\n",
    "    end_logits = outputs.end_logits[0]\n",
    "    \n",
    "    start_pred = torch.argmax(start_logits).item()\n",
    "    end_pred = torch.argmax(end_logits).item()\n",
    "    \n",
    "    # Fix invalid span\n",
    "    if end_pred < start_pred:\n",
    "        end_pred = start_pred\n",
    "    \n",
    "    score = start_logits[start_pred] + end_logits[end_pred]\n",
    "\n",
    "    # Decode prediction\n",
    "    prediction_text = tokenizer.decode(\n",
    "        encoded[\"input_ids\"][0][start_pred:end_pred + 1],\n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "\n",
    "    gold_text = example[\"answers\"][\"text\"][0]\n",
    "\n",
    "    # Exact Match → label binaire\n",
    "    y_true.append(int(prediction_text.strip() == gold_text.strip()))\n",
    "    y_scores.append(score.item())\n",
    "\n",
    "    # Build prediction and reference lists for metric.compute()\n",
    "    predictions.append({\n",
    "        \"id\": example[\"id\"],\n",
    "        \"prediction_text\": prediction_text\n",
    "    })\n",
    "    \n",
    "    references.append({\n",
    "        \"id\": example[\"id\"],\n",
    "        \"answers\": example[\"answers\"]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515e3d60",
   "metadata": {},
   "source": [
    "## Résultats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eefaca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 3.2, 'f1': 7.769248010515557}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = metric.compute(predictions=predictions, references=references)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0675e3d4",
   "metadata": {},
   "source": [
    "## Mesure du temps d’inférence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5492158a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016190597057342528"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for example in validation_set:\n",
    "    encoded = tokenizer(\n",
    "        example[\"question\"],\n",
    "        example[\"context\"],\n",
    "        truncation=True,\n",
    "        max_length=384,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**{k: v.to(device) for k, v in encoded.items()})\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "avg_time = (end_time - start_time) / n_samples\n",
    "avg_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02619df4",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Le modèle fine-tuné a été évalué sur le jeu de validation SQuAD.\n",
    "\n",
    "En plus des métriques Exact Match et F1, nous avons évalué les modèles\n",
    "à l'aide des métriques Precision, Recall et AUC.\n",
    "\n",
    "La courbe ROC permet d'analyser la capacité du modèle à distinguer\n",
    "les réponses correctes des réponses incorrectes en fonction d'un\n",
    "seuil de confiance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86cd691",
   "metadata": {},
   "source": [
    "## Résumé des résultats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ea60ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'DistilBERT',\n",
       " 'EM': 3.2,\n",
       " 'F1': 7.769248010515557,\n",
       " 'Precision': np.float64(0.0020408163265306124),\n",
       " 'Recall': np.float64(0.9979591836734694),\n",
       " 'AUC': nan,\n",
       " 'Inference_time_ms': 16.19059705734253}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_summary = {\n",
    "    \"model\": \"DistilBERT\",\n",
    "    \"EM\": results[\"exact_match\"],\n",
    "    \"F1\": results[\"f1\"],\n",
    "    \"Inference_time_ms\": avg_time * 1000\n",
    "}\n",
    "\n",
    "results_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b9065a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultats sauvegardés dans outputs/results_distilbert.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Sauvegarder les résultats en JSON\n",
    "with open(\"outputs/results_distilbert.json\", \"w\") as f:\n",
    "    json.dump(results_summary, f, indent=2)\n",
    "\n",
    "print(\"Résultats sauvegardés dans outputs/results_distilbert.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
