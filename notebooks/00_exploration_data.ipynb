{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e90915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2acc88e",
   "metadata": {},
   "source": [
    "# Question Answering ‚Äì Exploration du dataset SQuAD\n",
    "\n",
    "Ce notebook a pour objectif de charger et explorer le dataset SQuAD\n",
    "afin de comprendre la structure des donn√©es utilis√©es pour le\n",
    "fine-tuning de mod√®les Transformer en question answering extractif.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1b1a14",
   "metadata": {},
   "source": [
    "## Objectifs\n",
    "\n",
    "- Charger le dataset SQuAD √† l‚Äôaide de la librairie Hugging Face Datasets\n",
    "- Comprendre la structure des donn√©es (question, contexte, r√©ponse)\n",
    "- Visualiser des exemples concrets\n",
    "- Initialiser le tokenizer associ√© au mod√®le Transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3855bd38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aissi\\OneDrive - De Vinci\\A5\\UVSQ\\S2\\Fouille de donn√©es\\qa-project\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d83efca",
   "metadata": {},
   "source": [
    "## Chargement du dataset SQuAD\n",
    "\n",
    "Nous utilisons le dataset SQuAD (Stanford Question Answering Dataset),\n",
    "un jeu de donn√©es de r√©f√©rence pour le question answering extractif.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ef18ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"squad\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fd5814",
   "metadata": {},
   "source": [
    "## Structure du dataset\n",
    "\n",
    "Le dataset est compos√© de deux parties :\n",
    "- un ensemble d‚Äôentra√Ænement (`train`)\n",
    "- un ensemble de validation (`validation`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f32ceddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 87599\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9caa58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 10570\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"validation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a840d8b",
   "metadata": {},
   "source": [
    "## Exemple d‚Äôune entr√©e du dataset\n",
    "\n",
    "Chaque exemple contient :\n",
    "- un contexte (paragraphe)\n",
    "- une question\n",
    "- une ou plusieurs r√©ponses sous forme de span dans le contexte\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f284ad11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '5733be284776f41900661182',\n",
       " 'title': 'University_of_Notre_Dame',\n",
       " 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       " 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
       " 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd661fc2",
   "metadata": {},
   "source": [
    "## Conversion en DataFrame\n",
    "\n",
    "Pour faciliter l‚Äôexploration des donn√©es, nous convertissons le dataset\n",
    "en DataFrame pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fcea32d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>{'text': ['Saint Bernadette Soubirous'], 'answ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5733be284776f4190066117f</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>{'text': ['a copper statue of Christ'], 'answe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5733be284776f41900661180</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>{'text': ['the Main Building'], 'answer_start'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5733be284776f41900661181</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>{'text': ['a Marian place of prayer and reflec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5733be284776f4190066117e</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>{'text': ['a golden statue of the Virgin Mary'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id                     title  \\\n",
       "0  5733be284776f41900661182  University_of_Notre_Dame   \n",
       "1  5733be284776f4190066117f  University_of_Notre_Dame   \n",
       "2  5733be284776f41900661180  University_of_Notre_Dame   \n",
       "3  5733be284776f41900661181  University_of_Notre_Dame   \n",
       "4  5733be284776f4190066117e  University_of_Notre_Dame   \n",
       "\n",
       "                                             context  \\\n",
       "0  Architecturally, the school has a Catholic cha...   \n",
       "1  Architecturally, the school has a Catholic cha...   \n",
       "2  Architecturally, the school has a Catholic cha...   \n",
       "3  Architecturally, the school has a Catholic cha...   \n",
       "4  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                            question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                  What is the Grotto at Notre Dame?   \n",
       "4  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                                             answers  \n",
       "0  {'text': ['Saint Bernadette Soubirous'], 'answ...  \n",
       "1  {'text': ['a copper statue of Christ'], 'answe...  \n",
       "2  {'text': ['the Main Building'], 'answer_start'...  \n",
       "3  {'text': ['a Marian place of prayer and reflec...  \n",
       "4  {'text': ['a golden statue of the Virgin Mary'...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame(dataset[\"train\"])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4d4fda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.DataFrame(dataset[\"validation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000e531b",
   "metadata": {},
   "source": [
    "## Statistiques descriptives\n",
    "\n",
    "Pour comprendre les contraintes du dataset, nous analysons les longueurs\n",
    "des contextes et des questions (en nombre de mots).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04057e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des longueurs en mots\n",
    "train_df[\"context_len\"] = train_df[\"context\"].str.split().apply(len)\n",
    "train_df[\"question_len\"] = train_df[\"question\"].str.split().apply(len)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"LONGUEUR DES CONTEXTES (en mots)\")\n",
    "print(\"=\" * 60)\n",
    "print(train_df[\"context_len\"].describe())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"LONGUEUR DES QUESTIONS (en mots)\")\n",
    "print(\"=\" * 60)\n",
    "print(train_df[\"question_len\"].describe())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"NOMBRE MOYEN DE R√âPONSES PAR QUESTION\")\n",
    "print(\"=\" * 60)\n",
    "train_df[\"num_answers\"] = train_df[\"answers\"].apply(lambda x: len(x[\"text\"]))\n",
    "print(train_df[\"num_answers\"].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2e0507",
   "metadata": {},
   "source": [
    "## Visualisation des distributions\n",
    "\n",
    "Observons la distribution des longueurs pour mieux comprendre\n",
    "les caract√©ristiques du dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ebc57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogramme des longueurs de contexte\n",
    "axes[0].hist(train_df[\"context_len\"], bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].set_title(\"Distribution de la longueur des contextes\", fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel(\"Nombre de mots\")\n",
    "axes[0].set_ylabel(\"Fr√©quence\")\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Histogramme des longueurs de question\n",
    "axes[1].hist(train_df[\"question_len\"], bins=50, color='coral', edgecolor='black', alpha=0.7)\n",
    "axes[1].set_title(\"Distribution de la longueur des questions\", fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel(\"Nombre de mots\")\n",
    "axes[1].set_ylabel(\"Fr√©quence\")\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d14b31",
   "metadata": {},
   "source": [
    "## Analyse des r√©ponses\n",
    "\n",
    "Dans SQuAD, la r√©ponse n‚Äôest pas g√©n√©r√©e :\n",
    "elle correspond √† un **segment pr√©cis du contexte**.\n",
    "\n",
    "Chaque r√©ponse est d√©finie par :\n",
    "- le texte de la r√©ponse\n",
    "- l‚Äôindice de d√©but dans le contexte\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cc8c721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n",
      "Answer: Saint Bernadette Soubirous\n",
      "Answer start: 515\n",
      "Context snippet: Saint Bernadette Soubirous in 1858. At the end of \n"
     ]
    }
   ],
   "source": [
    "example = dataset[\"train\"][0]\n",
    "\n",
    "print(\"Question:\", example[\"question\"])\n",
    "print(\"Answer:\", example[\"answers\"][\"text\"][0])\n",
    "print(\"Answer start:\", example[\"answers\"][\"answer_start\"][0])\n",
    "print(\"Context snippet:\", example[\"context\"][example[\"answers\"][\"answer_start\"][0]:\n",
    "                                     example[\"answers\"][\"answer_start\"][0] + 50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c85ab14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rifier le nombre de r√©ponses possibles pour une question\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STRUCTURE MULTI-R√âPONSES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Nombre de r√©ponses pour cet exemple : {len(example['answers']['text'])}\")\n",
    "print(f\"R√©ponses possibles : {example['answers']['text']}\")\n",
    "\n",
    "print(\"\\nObservation sur le dataset complet :\")\n",
    "print(f\"Nombre moyen de r√©ponses par question : {train_df['num_answers'].mean():.2f}\")\n",
    "print(f\"Max r√©ponses par question : {train_df['num_answers'].max()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e7fac6",
   "metadata": {},
   "source": [
    "üí° **Importance des m√©triques adapt√©es** : \n",
    "Certaines questions poss√®dent plusieurs r√©ponses valides. C'est pourquoi \n",
    "nous utilisons des m√©triques comme l'Exact Match (EM) et le F1-score \n",
    "plut√¥t qu'une simple accuracy binaire.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34d874e",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "Nous utilisons le tokenizer associ√© au mod√®le Transformer.\n",
    "Le tokenizer permet de transformer le texte en tokens exploitables\n",
    "par le r√©seau de neurones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a797267",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8354fa27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2000, 3183, 2106, 1996, 6261, 2984, 9382, 3711, 1999, 8517, 1999, 10223, 26371, 2605, 1029, 102, 6549, 2135, 1010, 1996, 2082, 2038, 1037, 3234, 2839, 1012, 10234, 1996, 2364, 2311, 1005, 1055, 2751, 8514, 2003, 1037, 3585, 6231, 1997, 1996, 6261, 2984, 1012, 3202, 1999, 2392, 1997, 1996, 2364, 2311, 1998, 5307, 2009, 1010, 2003, 1037, 6967, 6231, 1997, 4828, 2007, 2608, 2039, 14995, 6924, 2007, 1996, 5722, 1000, 2310, 3490, 2618, 4748, 2033, 18168, 5267, 1000, 1012, 2279, 2000, 1996, 2364, 2311, 2003, 1996, 13546, 1997, 1996, 6730, 2540, 1012, 3202, 2369, 1996, 13546, 2003, 1996, 24665, 23052, 1010, 1037, 14042, 2173, 1997, 7083, 1998, 9185, 1012, 2009, 2003, 1037, 15059, 1997, 1996, 24665, 23052, 2012, 10223, 26371, 1010, 2605, 2073, 1996, 6261, 2984, 22353, 2135, 2596, 2000, 3002, 16595, 9648, 4674, 2061, 12083, 9711, 2271, 1999, 8517, 1012, 2012, 1996, 2203, 1997, 1996, 2364, 3298, 1006, 1998, 1999, 1037, 3622, 2240, 2008, 8539, 2083, 1017, 11342, 1998, 1996, 2751, 8514, 1007, 1010, 2003, 1037, 3722, 1010, 2715, 2962, 6231, 1997, 2984, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(example[\"question\"], example[\"context\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f67cba",
   "metadata": {},
   "source": [
    "## Tokenization avec contraintes de longueur\n",
    "\n",
    "Les contextes pouvant √™tre longs, nous appliquons :\n",
    "- une troncature\n",
    "- une longueur maximale\n",
    "- un padding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca5c1a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2000,  3183,  2106,  1996,  6261,  2984,  9382,  3711,  1999,\n",
       "          8517,  1999, 10223, 26371,  2605,  1029,   102,  6549,  2135,  1010,\n",
       "          1996,  2082,  2038,  1037,  3234,  2839,  1012, 10234,  1996,  2364,\n",
       "          2311,  1005,  1055,  2751,  8514,  2003,  1037,  3585,  6231,  1997,\n",
       "          1996,  6261,  2984,  1012,  3202,  1999,  2392,  1997,  1996,  2364,\n",
       "          2311,  1998,  5307,  2009,  1010,  2003,  1037,  6967,  6231,  1997,\n",
       "          4828,  2007,  2608,  2039, 14995,  6924,  2007,  1996,  5722,  1000,\n",
       "          2310,  3490,  2618,  4748,  2033, 18168,  5267,  1000,  1012,  2279,\n",
       "          2000,  1996,  2364,  2311,  2003,  1996, 13546,  1997,  1996,  6730,\n",
       "          2540,  1012,  3202,  2369,  1996, 13546,  2003,  1996, 24665, 23052,\n",
       "          1010,  1037, 14042,  2173,  1997,  7083,  1998,  9185,  1012,  2009,\n",
       "          2003,  1037, 15059,  1997,  1996, 24665, 23052,  2012, 10223, 26371,\n",
       "          1010,  2605,  2073,  1996,  6261,  2984, 22353,  2135,  2596,  2000,\n",
       "          3002, 16595,  9648,  4674,  2061, 12083,  9711,  2271,  1999,  8517,\n",
       "          1012,  2012,  1996,  2203,  1997,  1996,  2364,  3298,  1006,  1998,\n",
       "          1999,  1037,  3622,  2240,  2008,  8539,  2083,  1017, 11342,  1998,\n",
       "          1996,  2751,  8514,  1007,  1010,  2003,  1037,  3722,  1010,  2715,\n",
       "          2962,  6231,  1997,  2984,  1012,   102,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "    example[\"question\"],\n",
    "    example[\"context\"],\n",
    "    truncation=\"only_second\",\n",
    "    max_length=384,\n",
    "    stride=128,\n",
    "    padding=\"max_length\",\n",
    "    return_overflowing_tokens=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "print(\"Tok√©nisation avec contraintes :\")\n",
    "print(f\"  - max_length : 384\")\n",
    "print(f\"  - stride : 128 (pour les contextes d√©passant max_length)\")\n",
    "print(f\"  - return_overflowing_tokens : True (gestion des fen√™tres chevauchantes)\")\n",
    "print(f\"\\nR√©sultat :\")\n",
    "print(inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f80d4cb",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è **Attention : Risque de perte de r√©ponse**\n",
    "\n",
    "La troncature na√Øve (`truncation=True`) peut entra√Æner la **perte de la r√©ponse** \n",
    "si celle-ci se situe au-del√† de la fen√™tre tokenis√©e (position > max_length).\n",
    "\n",
    "C'est pourquoi le m√©canisme de **sliding window** (stride + overflowing tokens) \n",
    "est crucial : il cr√©e des fen√™tres chevauchantes pour s'assurer que \n",
    "chaque r√©ponse est capt√©e dans au moins une fen√™tre.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e5cf6e",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Ce notebook a permis d‚Äôexplorer le dataset SQuAD et de comprendre\n",
    "la structure des donn√©es utilis√©es pour le question answering extractif.\n",
    "\n",
    "La prochaine √©tape consistera √† pr√©parer les donn√©es pour\n",
    "l‚Äôentra√Ænement, en alignant les positions des r√©ponses avec les tokens\n",
    "produits par le tokenizer.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
